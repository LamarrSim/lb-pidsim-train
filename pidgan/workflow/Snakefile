from snakemake_storage_helper import smkstore
import os.path

configfile: "config/config.yaml"
include: "rules/storage.smk"

MODELS = ['isMuon', 'Rich', 'Muon', 'GlobalPID-im', 'GlobalPID-nm']
PARTICLES = ['muon', 'pion', 'kaon', 'proton']
ITEMS = ['model.keras', 'tX.pkl', 'tY.pkl']


rule validate_all:
    input: smkstore(expand("validate-{particle}.html", particle=PARTICLES), 's3reports')


rule build_apptainer_image:
  input:
    definition_file=ancient("workflow/envs/pidgan.def")

  output:
    sif=smkstore("lhcb-pidsim.sif", 's3images')

  params:
    unpacked=config['apptainer_image'],
    wait4cvfms=f"{config['cvmfs_repo']}/{config['apptainer_image']}",
    push=0, # Set to 1 to push to harbor

  shell:
    """
    apptainer build {output.sif} {input.definition_file}

    if [ {params.push} -eq 1 ]; then
      apptainer push  {output.sif} oras://{params.unpacked}

      echo "Waiting for cvmfs repo: {params.wait4cvfms}"
      while true; 
      do 
        ls {params.wait4cvfms} &> /dev/null || ( sleep 5 && echo "Still waiting..." ) ;
      done
    fi
    """


rule cache_container:
  input: smkstore("lhcb-pidsim.sif", 's3images')
  output: config['apptainer_cached_image']
  shell: "cp {input} {output}"

rule preprocessing:
    input: 
        image=config['apptainer_cached_image'],
        notebook="workflow/notebooks/{model}-preprocessing.ipynb",

    output:
        hook = touch("/tmp/preprocessing-{model}-{particle}.touch"),
        train=directory(config['temp_dir']+"/{model}-{particle}-train"),
        test=directory(config['temp_dir']+"/{model}-{particle}-test"),
        validation=directory(config['temp_dir']+"/{model}-{particle}-validation"),

        preprocessing_x=smkstore('{model}/{particle}/tX.pkl', 's3models'),
        preprocessing_y=smkstore('{model}/{particle}/tY.pkl', 's3models'),

        report=report(
            smkstore("{model}-{particle}-preprocessing.html", 's3reports'),
            category="Preprocessing",
            labels=dict(model="{model}", particle="{particle}", type='html')
        )

    log: smkstore("{model}-{particle}-preprocessing.html", 's3reports')
    
    container: config['apptainer_cached_image']

    params:
        data_files=lambda w: get_presigned_url(config['training_data'], 's3data'),
        sample=config['sample'],
        local="no",
        model=lambda w: w.model.upper().replace('-', '_'),
        additional_flags=config['nbconvert_args'],

    resources:
        cpu=8,
        mem_mb=32000,
        gpu=0

    shell:
        """
        INPUT_FILES='{params.data_files}' \
        TRAIN='{output.train}' \
        TEST='{output.test}' \
        VALIDATION='{output.validation}' \
        PARTICLE='{wildcards.particle}' \
        PREPROCESSING_X='{output.preprocessing_x}' \
        PREPROCESSING_Y='{output.preprocessing_y}' \
        jupyter nbconvert --to html --execute \
        --ExecutePreprocessor.timeout=-1 \
        --ExecutePreprocessor.kernel_name=python3 \
        --no-prompt \
        {params.additional_flags} \
        {input.notebook} --output {log}
        """


################################################################################

rule train:
    input: 
        image=config['apptainer_cached_image'],
        notebook="workflow/notebooks/{model}-train.ipynb",
        model_yaml_file=os.path.join(workflow.basedir, "notebooks/models.yaml"),
        training_data=config['temp_dir']+"/{model}-{particle}-train",
        validation_data=config['temp_dir']+"/{model}-{particle}-validation",
        test_data=config['temp_dir']+"/{model}-{particle}-test",
        preprocessing_x=smkstore('{model}/{particle}/tX.pkl', 's3models'),
        preprocessing_y=smkstore('{model}/{particle}/tY.pkl', 's3models'),
        

    output:
        hook = touch("/tmp/train-{model}-{particle}.touch"),

        generator_png=touch(config['temp_dir'] + "/images/generator-{model}-{particle}.png"),
        discriminator_png=touch(config['temp_dir'] + "/images/discriminator-{model}-{particle}.png"),
        referee_png=touch(config['temp_dir'] + "/images/referee-{model}-{particle}.png"),

        history_csv=report(
            smkstore("history/generator-{model}-{particle}.csv", 's3reports'),
            category="Training",
            labels=dict(model="{model}", particle="{particle}", type='csv')
        ),

        output_validation_set=smkstore("ready2validate/{model}-{particle}.npz", 's3reports'),
        output_model=smkstore("{model}/{particle}/model.keras", "s3models"),

        report=report(
            smkstore("{model}-{particle}-train.html", 's3reports'),
            category="Preprocessing",
            labels=dict(model="{model}", particle="{particle}", type='html')
        )

    log: smkstore("{model}-{particle}-train.html", 's3reports')
    
    container: config['apptainer_cached_image']


    resources:
        cpu=8,
        mem_mb=32000,
        gpu=1

    params:
        sample=config['sample'],
        local="no",
        model=lambda w: w.model.upper().replace('-', '_'),
        particle=lambda w: w.particle.upper().replace('-', '_'),
        max_epochs=str(1000),
        max_files=str(2),
        training_time_limit_seconds=str(config['training_time_limit_seconds']),
        additional_flags=config['nbconvert_args'],
        

    shell:
        """
        LOCAL=no \
        TEST=no \
        SAMPLE='{params.sample}' \
        PARTICLE='{wildcards.particle}' \
        {params.model}_TRAIN_DATA='{input.training_data}' \
        {params.model}_TEST_DATA='{input.test_data}' \
        {params.model}_VAL_DATA='{input.validation_data}' \
        MODEL_YAML_FILE='{input.model_yaml_file}' \
        PNG_GENERATOR='{output.generator_png}' \
        PNG_DISCRIMINATOR='{output.discriminator_png}' \
        PNG_REFEREE='{output.referee_png}' \
        MAX_EPOCHS='{params.max_epochs}' \
        MAX_FILES='{params.max_files}' \
        TRAINING_TIME_LIMIT_SECONDS='{params.training_time_limit_seconds}' \
        HISTORY_CSV='{output.history_csv}' \
        {params.model}_PREPROCESSING_{params.particle}_X='{input.preprocessing_x}' \
        {params.model}_PREPROCESSING_{params.particle}_Y='{input.preprocessing_y}' \
        OUTPUT_VALIDATION_DATASET='{output.output_validation_set}' \
        OUTPUT_MODEL='{output.output_model}' \
        jupyter nbconvert --to html --execute \
        --ExecutePreprocessor.timeout=-1 \
        --ExecutePreprocessor.kernel_name=python3 \
        --no-prompt \
        {params.additional_flags} \
        {input.notebook} --output {log}
        """

rule deploy:
    input:
        image=config['apptainer_cached_image'],
        notebook="workflow/notebooks/Deploy.ipynb",
        models=smkstore(
            expand("{model}/{particle}/{item}", model=MODELS, particle=PARTICLES, item=ITEMS),
            's3models',
        ),
      
    output:
        hook=touch("/tmp/deploy.touch"),
        generated_c_file="/tmp/compiled_model.c",
        generated_library=smkstore("pid_compiled_model/generated.so", 's3models'),
        report=report(
            smkstore("deploy.html", 's3reports'),
            category="Deploy",
            labels=dict(model="ALL", particle="ALL", type='html')
        )

    params:
        sample=config['sample'],
        additional_flags=config['nbconvert_args'],
        env_vars=[
                f"{model.upper().replace('-', '_')}_{particle.upper()}_MODEL="+
                smkstore(f"{model}/{particle}/model.keras", "s3models")
                for model in MODELS for particle in PARTICLES 
            ],

    log: smkstore("deploy.html", 's3reports')

    container: config['apptainer_cached_image']

    shell:
        """
        LOCAL=no \
        TEST=no \
        SAMPLE='{params.sample}' \
        {params.env_vars} \
        GENERATED_LIBRARY='{output.generated_library}' \
        GENERATED_C_FILE='{output.generated_c_file}' \
        jupyter nbconvert --to html --execute \
        --ExecutePreprocessor.timeout=-1 \
        --ExecutePreprocessor.kernel_name=python3 \
        --no-prompt \
        {params.additional_flags} \
        {input.notebook} --output {log}
        """

################################################################################

rule validate:
    input: 
        image=config['apptainer_cached_image'],
        notebook="workflow/notebooks/validate.ipynb",
        generated_library=smkstore("pid_compiled_model/generated.so", 's3models'),

    output:
        hook=touch("/tmp/validate-{particle}.touch"),

        report=report(
            smkstore("validate-{particle}.html", 's3reports'),
            category="Validation",
            labels=dict(model="ALL", particle="{particle}", type="html")
        )

    log: smkstore("validate-{particle}.html", 's3reports')
    
    container: config['apptainer_cached_image']

    params:
        data_files=lambda w: get_presigned_url(config['training_data'], 's3data'),
        sample=config['sample'],
        local="no",
        additional_flags=config['nbconvert_args'],
        max_entries=config['entries_for_validation'],

    resources:
        cpu=8,
        mem_mb=32000,
        gpu=0

    shell:
        """
        INPUT_FILES='{params.data_files}' \
        PARTICLE='{wildcards.particle}' \
        SHARED_OBJECT='{input.generated_library}' \
        MAX_ENTRIES='{params.max_entries}' \
        SAMPLE='{params.sample}' \
        jupyter nbconvert --to html --execute \
        --ExecutePreprocessor.timeout=-1 \
        --ExecutePreprocessor.kernel_name=python3 \
        --no-prompt \
        {params.additional_flags} \
        {input.notebook} --output {log}
        """


        
