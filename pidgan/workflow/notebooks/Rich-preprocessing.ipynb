{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps for _RICH_ models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       " * PARTICLE: `muon`\n",
       " * LOCAL: `True`\n",
       " * SAMPLE: `2016MU`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import Markdown\n",
    "\n",
    "PARTICLE = os.environ.get(\"PARTICLE\", \"muon\")\n",
    "LOCAL = os.environ.get(\"LOCAL\", \"yes\").lower() in ['y', 'yes', 'true', '1']\n",
    "SAMPLE = os.environ.get(\"SAMPLE\", \"2016MU\")\n",
    "\n",
    "Markdown(f\"\"\"\n",
    " * PARTICLE: `{PARTICLE}`\n",
    " * LOCAL: `{LOCAL}`\n",
    " * SAMPLE: `{SAMPLE}`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technologies and libraries\n",
    "\n",
    "On top of the standard Python echosystem we are using:\n",
    " * `uproot` to convert data from `ROOT TTrees` to `pandas DataFrames`\n",
    " * `dask DataFrame` to enable processing datasets larger than the available RAM. Dask takes care of flushing from disk to RAM the data, converting from ROOT to pandas data format on demand.\n",
    " * `Arrow Feather` data format to cache in local storage the training dataset\n",
    "     * Note that custom wrappers to Dask and TensorFlow, as defined in `feather_io.py` are needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 data files\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "if LOCAL:\n",
    "    if SAMPLE == \"2016MU\":\n",
    "        file_pattern = \"/tmp/LamarrTraining-j109*.root\"\n",
    "        default_file_list = glob(file_pattern)[:3]\n",
    "else:\n",
    "    # file_pattern = \"/workarea/cloud-storage/anderlinil/LamarrBenderTrain/j109/*.root\"\n",
    "    default_file_list = []\n",
    "    \n",
    "file_list = os.environ.get(\"INPUT_FILES\", \" \".join(default_file_list)).split(\" \")\n",
    "\n",
    "print (f\"Found {len(file_list)} data files\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion from `ROOT TTree` to `Pandas DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections = [\n",
    "    \"probe_Brunel_P > 3000\",\n",
    "    \"probe_Brunel_P < 200000\", \n",
    "    \"probe_Brunel_ETA > 1.5\",\n",
    "    \"probe_Brunel_ETA < 5.5\", \n",
    "    \"probe_Brunel_RichDLLe  > -150\",\n",
    "    \"probe_Brunel_RichDLLmu > -150\",\n",
    "    \"probe_Brunel_RichDLLk  > -150\",\n",
    "    \"probe_Brunel_RichDLLp  > -150\",\n",
    "    \"probe_Brunel_RichDLLe  <  150\",\n",
    "    \"probe_Brunel_RichDLLmu <  150\",\n",
    "    \"probe_Brunel_RichDLLk  <  150\",\n",
    "    \"probe_Brunel_RichDLLp  <  150\",\n",
    "    \"nTracks_Brunel > 0\",\n",
    "    \"nTracks_Brunel < 1000\", \n",
    "]\n",
    "\n",
    "cuts = \" and \".join([f\"({s})\" for s in selections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/private/lamarr/lb-pidsim-train/pidgan/workflow/notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m opened_files = [\u001b[43muproot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m file_list]\n\u001b[32m      5\u001b[39m sim = (\n\u001b[32m      6\u001b[39m     ddf.from_map(\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m f: pd.DataFrame(f[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPidTupler/pid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPARTICLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m].arrays(library=\u001b[33m'\u001b[39m\u001b[33mnp\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m      8\u001b[39m         opened_files,\n\u001b[32m      9\u001b[39m     ).query(cuts)\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/uproot/reading.py:142\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[33m\"\u001b[39m\u001b[33mseek\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    135\u001b[39m ):\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    137\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a string, pathlib.Path, an object with \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mseek\u001b[39m\u001b[33m'\u001b[39m\u001b[33m methods, or a length-1 dict of \u001b[39m\u001b[33m{\u001b[39m\u001b[33mfile_path: object_path}, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m file = \u001b[43mReadOnlyFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobject_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43marray_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43marray_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m object_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file.root_directory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/uproot/reading.py:573\u001b[39m, in \u001b[36mReadOnlyFile.__init__\u001b[39m\u001b[34m(self, file_path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mbegin_chunk_size\u001b[39m\u001b[33m\"\u001b[39m] < _file_header_fields_big.size:\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    567\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbegin_chunk_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is not enough to read the TFile header (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    568\u001b[39m             \u001b[38;5;28mself\u001b[39m._options[\u001b[33m\"\u001b[39m\u001b[33mbegin_chunk_size\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    569\u001b[39m             _file_header_fields_big.size,\n\u001b[32m    570\u001b[39m         )\n\u001b[32m    571\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m \u001b[38;5;28mself\u001b[39m._begin_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_source\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbegin_chunk_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.detach_memmap()\n\u001b[32m    577\u001b[39m \u001b[38;5;28mself\u001b[39m.hook_before_interpret()\n\u001b[32m    579\u001b[39m (\n\u001b[32m    580\u001b[39m     magic,\n\u001b[32m    581\u001b[39m     \u001b[38;5;28mself\u001b[39m._fVersion,\n\u001b[32m   (...)\u001b[39m\u001b[32m    595\u001b[39m     \u001b[38;5;28mself\u001b[39m._begin_chunk, _file_header_fields_small, {}\n\u001b[32m    596\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/uproot/source/fsspec.py:95\u001b[39m, in \u001b[36mFSSpecSource.chunk\u001b[39m\u001b[34m(self, start, stop)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28mself\u001b[39m._num_requested_chunks += \u001b[32m1\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mself\u001b[39m._num_requested_bytes += stop - start\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m future = uproot.source.futures.TrivialFuture(data)\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m uproot.source.chunk.Chunk(\u001b[38;5;28mself\u001b[39m, start, stop, future)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/fsspec/spec.py:797\u001b[39m, in \u001b[36mAbstractFileSystem.cat_file\u001b[39m\u001b[34m(self, path, start, end, **kwargs)\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the content of a file\u001b[39;00m\n\u001b[32m    786\u001b[39m \n\u001b[32m    787\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    794\u001b[39m \u001b[33;03mkwargs: passed to ``open()``.\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    796\u001b[39m \u001b[38;5;66;03m# explicitly set buffering off?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    798\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    799\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m start >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/fsspec/spec.py:1338\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1337\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1347\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/fsspec/implementations/local.py:206\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/fsspec/implementations/local.py:383\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;28mself\u001b[39m.compression = get_compression(path, compression)\n\u001b[32m    382\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/fsspec/implementations/local.py:388\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f.closed:\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m         \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n\u001b[32m    390\u001b[39m             compress = compr[\u001b[38;5;28mself\u001b[39m.compression]\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: '/home/private/lamarr/lb-pidsim-train/pidgan/workflow/notebooks'"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "opened_files = [uproot.open(f) for f in file_list]\n",
    "\n",
    "sim = (\n",
    "    ddf.from_map(\n",
    "        lambda f: pd.DataFrame(f[f\"PidTupler/pid_{PARTICLE}\"].arrays(library='np')),\n",
    "        opened_files,\n",
    "    ).query(cuts)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML (\"<UL>\" + \"\\n\".join(f\"<LI> <PRE>{var}</PRE> \" for var in sim.columns) + \"</UL>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim[\"p_GeV\"] = sim.probe_Brunel_P/1e3\n",
    "# sim[\"log10_p\"] = np.log10(sim.probe_Brunel_P)\n",
    "sim[\"eta\"] = sim.probe_Brunel_ETA\n",
    "sim = sim.map_partitions(lambda df: df.assign(nTracks_f = df.nTracks_Brunel + np.random.uniform(-0.5, 0.5, len(df))))\n",
    "sim[\"charge\"] = sim.probe_Brunel_trackcharge\n",
    "\n",
    "sim[\"RichDLLe\"] = sim.probe_Brunel_RichDLLe\n",
    "sim[\"RichDLLmu\"] = sim.probe_Brunel_RichDLLmu\n",
    "sim[\"RichDLLk\"] = sim.probe_Brunel_RichDLLk\n",
    "sim[\"RichDLLp\"] = sim.probe_Brunel_RichDLLp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_conditions = [\"p_GeV\", \"eta\", \"nTracks_f\"]\n",
    "flag_conditions = [\"charge\"]\n",
    "\n",
    "conditions = real_conditions + flag_conditions\n",
    "target = [\"RichDLLe\", \"RichDLLmu\", \"RichDLLk\", \"RichDLLp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def list_vars(title, var_list):\n",
    "    display(HTML (f\"<P><B>{title}</B><UL>\" + \"\\n\".join(f\"<LI> <PRE>{var}</PRE> \" for var in var_list) + \"</UL><HR>\"))\n",
    "\n",
    "list_vars(\"Input features (real)\", real_conditions)\n",
    "list_vars(\"Input features (boolean)\", flag_conditions)\n",
    "list_vars(\"Output features (real)\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dict()\n",
    "npartitions=min(len(file_list), 10)\n",
    "\n",
    "dfs = sim[conditions + target].head(500_000, npartitions=npartitions)\n",
    "print(f\"Number of {PARTICLE}s:\", len(dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(24, 5), dpi=100)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.xlabel(r\"$p$ [GeV/$c$]\", fontsize=12)\n",
    "plt.ylabel(r\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"p_GeV\"], bins=np.linspace(1.0, 101.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.xlabel(r\"$\\eta$\", fontsize=12)\n",
    "plt.ylabel(\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"eta\"], bins=np.linspace(1.5, 5.5, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.xlabel(r\"$\\mathtt{nTracks}$\", fontsize=12)\n",
    "plt.ylabel(\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"nTracks_f\"], bins=np.linspace(0.0, 500.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 10), dpi=100)\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.xlabel(r\"$\\mathtt{RichDLLe}$\", fontsize=12)\n",
    "plt.ylabel(r\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"RichDLLe\"], bins=np.linspace(-150.0, 100.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.xlabel(r\"$\\mathtt{RichDLLmu}$\", fontsize=12)\n",
    "plt.ylabel(r\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"RichDLLmu\"], bins=np.linspace(-100.0, 150.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.xlabel(r\"$\\mathtt{RichDLLmue}$\", fontsize=12)\n",
    "plt.ylabel(r\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"RichDLLmu\"] - dfs[\"RichDLLe\"], bins=np.linspace(-50.0, 150.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.xlabel(r\"$\\mathtt{RichDLLk}$\", fontsize=12)\n",
    "plt.ylabel(r\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"RichDLLk\"], bins=np.linspace(-150.0, 100.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.xlabel(r\"$\\mathtt{RichDLLp}$\", fontsize=12)\n",
    "plt.ylabel(r\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"RichDLLp\"], bins=np.linspace(-150.0, 100.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.xlabel(r\"$\\mathtt{RichDLLpk}$\", fontsize=12)\n",
    "plt.ylabel(r\"Candidates\", fontsize=12)\n",
    "plt.hist(dfs[\"RichDLLp\"] - dfs[\"RichDLLk\"], bins=np.linspace(-100.0, 100.0, 101), histtype=\"step\", lw=2, label=PARTICLE)\n",
    "plt.legend(fontsize=10)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "\n",
    "n_features = len(real_conditions)\n",
    "n_flags = len(flag_conditions)\n",
    "n_target = len(target)\n",
    "\n",
    "prep_step_x = dict()\n",
    "\n",
    "prep_step_x = ColumnTransformer(\n",
    "    [\n",
    "        ('features', QuantileTransformer(output_distribution='normal'), np.arange(n_features)),\n",
    "        ('flags', \"passthrough\", n_features + np.arange(n_flags)),\n",
    "    ]\n",
    ").fit(dfs[conditions].values)\n",
    "\n",
    "prep_step_y = dict()\n",
    "# prep_step_y = StandardScaler().fit(dfs[target].values)\n",
    "prep_step_y = QuantileTransformer(output_distribution='normal').fit(dfs[target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_utils import store_as_pickle\n",
    "\n",
    "display(\n",
    "    store_as_pickle(\n",
    "        prep_step_x,\n",
    "        f\"PREPROCESSING_X\",\n",
    "        f\"/tmp/lb-pidsim-train/models/Rich_{PARTICLE}_models/tX_{SAMPLE}.pkl\",\n",
    "    )\n",
    ")\n",
    "display(\n",
    "    store_as_pickle(\n",
    "        prep_step_y,\n",
    "        f\"PREPROCESSING_Y\",\n",
    "        f\"/tmp/lb-pidsim-train/models/Rich_{PARTICLE}_models/tY_{SAMPLE}.pkl\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test and validation\n",
    "\n",
    "The dataset is split in:\n",
    " * *train* (50%) used for training the model\n",
    " * *test* (40%) used for measuring the performance of the model\n",
    " * *validation* (10%) used in combination with the train dataset to check for overtraining effects\n",
    " \n",
    "Split data is stored on disk in chunks of 100 MB (before compression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.environ.get(\"DATA_PATH\", \"/tmp/lb-pidsim-train/data\")\n",
    "os.makedirs(DATA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_utils import split_and_store, peek_from_dataset\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(f\"# {PARTICLE.capitalize()}\"))\n",
    "\n",
    "entries = split_and_store(\n",
    "    sim[conditions + target],\n",
    "    [\n",
    "        (0.5, os.environ.get(f\"TRAIN\", f\"{DATA_PATH}/Rich-{PARTICLE}-{SAMPLE}-train\")),\n",
    "        (0.4, os.environ.get(f\"TEST\", f\"{DATA_PATH}/Rich-{PARTICLE}-{SAMPLE}-test\")),\n",
    "        (0.1, os.environ.get(f\"VALIDATION\", f\"{DATA_PATH}/Rich-{PARTICLE}-{SAMPLE}-validation\"))\n",
    "    ],\n",
    "    chunksize=\"80MB\",\n",
    "    features=conditions,\n",
    "    labels=target,\n",
    "    preprocessorX=prep_step_x,\n",
    "    preprocessorY=prep_step_y,\n",
    ")\n",
    "    \n",
    "display(pd.DataFrame(entries, index=[\"Train\", \"Test\", \"Validation\"]))\n",
    "\n",
    "X, y = peek_from_dataset(      \n",
    "    f\"TRAIN\", \n",
    "    f\"{DATA_PATH}/Rich-{PARTICLE}-{SAMPLE}-train\",\n",
    ")\n",
    " \n",
    "## X Variables\n",
    "plt.figure(figsize=(32, 5), dpi=100)\n",
    "\n",
    "for i, x_var in enumerate(conditions):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.xlabel(x_var, fontsize=12)\n",
    "    plt.ylabel(\"Candidates\", fontsize=12)\n",
    "    plt.hist(X[:, i].numpy()[:100000], bins=100)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "## RichDLL\n",
    "plt.figure(figsize=(24, 10), dpi=100)\n",
    "\n",
    "for i, y_var in enumerate([\"RichDLLe\", \"RichDLLmu\"]):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.xlabel(y_var, fontsize=12)\n",
    "    plt.ylabel(\"Candidates\", fontsize=12)\n",
    "    plt.hist(y[:, i].numpy()[:100000], bins=100)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.xlabel(\"RichDLLmue\", fontsize=12)\n",
    "plt.ylabel(\"Candidates\", fontsize=12)\n",
    "plt.hist(y[:, 1].numpy()[:100000] - y[:, 0].numpy()[:100000], bins=100)\n",
    "\n",
    "for i, y_var in enumerate([\"RichDLLk\", \"RichDLLp\"], 2):\n",
    "    plt.subplot(2, 3, i+2)\n",
    "    plt.xlabel(y_var, fontsize=12)\n",
    "    plt.ylabel(\"Candidates\", fontsize=12)\n",
    "    plt.hist(y[:, i].numpy()[:100000], bins=100)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.xlabel(\"RichDLLpk\", fontsize=12)\n",
    "plt.ylabel(\"Candidates\", fontsize=12)\n",
    "plt.hist(y[:, 3].numpy()[:100000] - y[:, 2].numpy()[:100000], bins=100)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lb-pidsim-train",
   "language": "python",
   "name": "lb-trksim-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
